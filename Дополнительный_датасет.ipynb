{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install pyLDAvis"
      ],
      "metadata": {
        "id": "EEO8l32yHmy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aka1KDWAGeN-"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import string \n",
        "import nltk\n",
        "nltk.download('stopwords') \n",
        "nltk.download('wordnet')\n",
        "nltk.download('cmudict')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "    \n",
        "haiku_file = 'all_haiku.csv'  # File location\n",
        "df = pd.read_csv(haiku_file)  # convert CSV file to pandas dataframe for workability\n",
        "\n",
        "\n",
        "# Tokens for BERT\n",
        "CLS = '<s>'\n",
        "SEP = '</s>'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "max_rows = 34000\n",
        "\n",
        "\n",
        "df.head()\n",
        "\n",
        "\n",
        "df = df.drop(columns=df.columns[0]) \n",
        "df.drop(index=df.index[max_rows:], \n",
        "        axis=0, \n",
        "        inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "0cR67VaDHdBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cmu_dict = cmudict.dict()\n",
        "words_not_in_cmu = []\n",
        "\n",
        "def num_syllables_word(word):\n",
        "    try:\n",
        "        \n",
        "        return [len(list(y for y in x if y[-1].isdigit())) for x in cmu_dict[word.lower()]][0]\n",
        "    except:\n",
        "        \n",
        "        words_not_in_cmu.append(word)\n",
        "        return -1\n",
        "\n",
        "def has_correct_syllables(haiku):\n",
        "    for i, sentence in enumerate(haiku):\n",
        "        num_syllabes = 0\n",
        "        try:\n",
        "            for word in sentence.split():\n",
        "                num_s =  num_syllables_word(word)\n",
        "                if num_s != -1:\n",
        "                    num_syllabes += num_syllables_word(word)\n",
        "                else:\n",
        "                    return False\n",
        "            if i == 0 or i == 2:\n",
        "                if num_syllabes != 5:\n",
        "                    return False\n",
        "            elif i == 1:\n",
        "                if num_syllabes != 7:\n",
        "                    return False\n",
        "                    break\n",
        "        except:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "df.replace('^ +| +$|\\'$|\\$', '', regex=True, inplace=True)\n",
        "\n",
        "words_not_in_cmu = []\n",
        "\n",
        "\n",
        "nrows = df.shape[0]\n",
        "df.drop(index=df.index[nrows:], inplace=True) \n",
        "\n",
        "\n",
        "df.replace('-{2,}|â€”|-$|- |~|\"|\\.|;|^ +| +$|\\'$', '', regex=True, inplace=True) \n",
        "\n",
        "for columns in df[['0','1','2']]:\n",
        "    df[columns] = df[columns].str.lower()\n",
        "\n",
        "\n",
        "all_haikus = df[['0','1','2']].to_numpy()\n",
        "df = df[[has_correct_syllables(haiku) for haiku in all_haikus]]\n",
        "df\n",
        "\n"
      ],
      "metadata": {
        "id": "ao6TDWcqHgAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "id": "VgzOKaaVH3X0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "df.to_excel(\"extraDataset.xlsx\")\n",
        "files.download(\"extraDataset.xlsx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "G7JKGzb-KnuB",
        "outputId": "9c56d596-cdfe-48c7-b8e5-bfd2e16131ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ebbe1fae-680a-4663-b764-b621b146584a\", \"extraDataset.xlsx\", 195793)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}